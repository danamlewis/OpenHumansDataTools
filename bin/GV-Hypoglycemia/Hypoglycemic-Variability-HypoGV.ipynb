{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cebb61a",
   "metadata": {},
   "source": [
    "# Data Import and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04097f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import cgmquantify as cgm\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9047dd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "PATH = r'' #Define path to all glucose entries files\n",
    "EXTENSION = 'csv'\n",
    "RANGES = [0,70,180,350] # Define store Glucose ranges\n",
    "\n",
    "# Get files and IDs\n",
    "files = glob.glob(os.path.join(PATH, f'*.{EXTENSION}'))\n",
    "ids = [os.path.basename(f).split('_entries', 1)[0].lstrip('0') for f in files]\n",
    "files_id = pd.DataFrame({'id': ids})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c30b05",
   "metadata": {},
   "source": [
    "# Defining the process_file function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9fb85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(f, BL_lower_lim, BL_upper_lim):\n",
    "    \"\"\"\n",
    "    Function to read and preprocess the data file\n",
    "\n",
    "    Parameters:\n",
    "    f (str): path to the data file\n",
    "    BL_lower_lim (float): lower limit for bad low glucose values\n",
    "    BL_upper_lim (float): upper limit for bad low glucose values\n",
    "\n",
    "    Returns:\n",
    "    df (pandas.DataFrame): preprocessed data\n",
    "\n",
    "    Example:\n",
    "    df = process_file('data.csv', 55, 70)\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(f, index_col=None, na_values=\" null\")\n",
    "    df = df.rename(columns={'Timestamp': 'Time', 'glucose': 'Glucose'})\n",
    "    df.index = pd.to_datetime(df[\"Time\"], format='%Y-%m-%d %H:%M:%S') \n",
    "    df = df.loc[~df.index.duplicated(keep='first')] # remove duplicate indexes\n",
    "    df = df.replace([np.inf, -np.inf], np.nan).dropna() # Replace infinite data with nan and drop rows with NaN\n",
    "    df = df.loc[df['Glucose'].between(40, 1000)] # Keep only glucose values between 40 and 1000\n",
    "    df.loc[df['Glucose'] > 400, 'Glucose'] = 400 # Replace glucose values greater than 400 with 400\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df['low'] = df['Glucose'].where(df['Glucose'].between(BL_lower_lim, BL_upper_lim)) # Mark values between the BL limits\n",
    "\n",
    "    # Assign bin level (ranges) to Glucose values\n",
    "    df['ranges'] = pd.cut(df['Glucose'], bins=RANGES)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bda20ac",
   "metadata": {},
   "source": [
    "# Defining the hypoGV function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cb537c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def hypoGV(df, t_range, direction):\n",
    "    \"\"\"\n",
    "    Function to calculate the Out-of-Whack Glycemic Variability metrics\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): preprocessed data from process_file function\n",
    "    t_range (int): range of data points to consider after each bad low event\n",
    "    direction (str): either 'forward' (after hypo event) or 'backward' (before hypo event)\n",
    "\n",
    "    Returns:\n",
    "    stats (list): a list of mean metric values\n",
    "\n",
    "    Example:\n",
    "    stats = hypoGV(df, 144, 'backward')\n",
    "    \"\"\"\n",
    "    # Prepare to store metrics before and after a bad low\n",
    "    metrics = {name: [] for name in ['TORless70', 'TIR', 'TORmore180', 'stdd', 'POR', 'J_index', 'LBGI', 'HBGI', 'GMI']}\n",
    "    \n",
    "    for ind, row in df.loc[~df['low'].isna()].iterrows(): # For each bad low, iteratively process the data\n",
    "        if direction == 'forward' and ind + t_range < len(df):\n",
    "            df2 = df.loc[ind:ind+t_range] # Slice dataframe forward\n",
    "        elif direction == 'backward' and ind - t_range >= 0:\n",
    "            df2 = df.loc[ind-t_range:ind] # Slice dataframe backward\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        df2.index = pd.to_datetime(df2[\"Time\"], format='%Y-%m-%d %H:%M:%S') # Reindex with timestamps for using cgmquantify formulas\n",
    "\n",
    "        # Calculate TIR and TOR ranges\n",
    "        result = df2.groupby([pd.Grouper(key=\"Time\"),\"ranges\"])[\"ranges\"].count().unstack(0).T.fillna(0)\n",
    "        summed_results = result.sum()\n",
    "        metrics['TORless70'].append(summed_results.iloc[0]/summed_results.sum()*100)\n",
    "        metrics['TIR'].append(summed_results.iloc[1]/summed_results.sum()*100)\n",
    "        metrics['TORmore180'].append(summed_results.iloc[2]/summed_results.sum()*100)\n",
    "            \n",
    "        # Calculate other variability metrics\n",
    "        metrics['stdd'].append(df2['Glucose'].std())\n",
    "        metrics['POR'].append(cgm.POR(df2))\n",
    "        metrics['J_index'].append(cgm.J_index(df2))\n",
    "        metrics['LBGI'].append(cgm.LBGI(df2))\n",
    "        metrics['HBGI'].append(cgm.HBGI(df2))\n",
    "        metrics['GMI'].append(cgm.GMI(df2))\n",
    "\n",
    "    # Calculate mean metrics for each patient\n",
    "    stats = [mean(values) for values in metrics.values()]\n",
    "\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f13fc7b",
   "metadata": {},
   "source": [
    "# Invoking Functions and Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ce1974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each file and calculate stats\n",
    "all_stats = [hypoGV(process_file(f, BL_lower_lim=55, BL_upper_lim=70), t_range=144, direction='backward') for f in files]\n",
    "\n",
    "# Convert mean variability to df and assign column names\n",
    "statistics = pd.DataFrame(all_stats, columns=['Mean STD', 'Mean TOR<70 [%]', 'Mean TIR [%]', 'Mean TOR>180 [%]', 'Mean POR', 'Mean J_index', 'Mean LGBI', 'Mean HBGI', 'Mean GMI'])\n",
    "\n",
    "statistics_with_ids = pd.concat([files_id, statistics], axis=1)\n",
    "\n",
    "statistics_with_ids"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
